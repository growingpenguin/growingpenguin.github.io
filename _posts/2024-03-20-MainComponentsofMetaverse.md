---
layout: post
title:  "Main Components of Metaverse"
---

# Main Components of Metaverse
**Recap of Metaverse** <br/>
Do not want to deal with high data rate, wnat to deal with a lower data rate and try increase user experience <br/>
**Device Level** <br/>
Visual interface <br/>
### Step-by-Step Metaverse <br/>
**Basic Diagram of System** <br/>
![MainComponentsofMetaverse1](https://github.com/growingpenguin/growingpenguin.github.io/assets/110277903/9aeefda0-7dc1-4d39-8714-6658a6c5baf5) <br/>
Input <-> System <-> Output <Br/>
Bidirectional Relationship <br/>
Output can go to input, and input can go to output <br/>
Input cases can be a physical format of the human <br/>
**Output** <br/>
With generalization, output can be three types <br/>
â†’ 1) Within the platform, 2) Users, 3) Objects <br/>
1) Within the platform <br/>
![MainComponentsofMetaverse2](https://github.com/growingpenguin/growingpenguin.github.io/assets/110277903/22a258f0-d3aa-4b99-a4c7-ee622b10778d) <br/>
2) Users <br/>
![MainComponentsofMetaverse3](https://github.com/growingpenguin/growingpenguin.github.io/assets/110277903/3db0ac92-d1a9-4530-a611-2fdfe78f27e3) <br/>

### More Details. More Interfaces
**User** <br/>
Starting point of the interaction <br/>
User interacts with the system through various devices <br/>
**Device** <br/>
The hardware or peripherals the user employs to interact with the system <br/>
Divided into four types of inputs <br/>
Audio: Sound inputs, possibly referring to voice commands or audio signals <br/>
Visual: Visual inputs, like a camera feed or screen display <br/>
Haptic: Touch or vibration-based inputs, such as a touchscreen or a controller with feedback <br/>
Gesture: Motion inputs, like hand or body movemen <br/>
Interface: <br/>
The means through which the user's inputs are translated into a form that the system can process. There is an interface between the user and the system (not explicitly labeled), and another within the system itself <br/>
Connection: <br/>
The double-headed arrows indicate a two-way connection, suggesting that data flows back and forth between the user and the system, as well as between the system and the output <br/>
**System**: <br/>
The core processing unit that interprets user input <br/>
Within the system, there are: <br/>
Apps: <br/>
Individual applications that use the system's resources <br/>
Graphic Module:<br/>
A component likely responsible for rendering graphics <br/>
Virtual Env. (Virtual Environment): <br/>
A digital space where interactions take place, such as a game or simulation <br/>
Management Layer:  <br/>
Operating system or software layer that manages the resources and processes of the system <br/>
Output:  <br/>
Result of the system processing the user's input <br/>
The output is shown here as a series of applications (App 1, App 2, etc.) that are presumably being displayed or utilized on a physical object, such as a computer monitor <br/>
-User Interfaces & Graphical Interfaces and Environments: <br/>
Various interfaces that a user interacts with, including both the user interfaces (UI) that handle the input and output between the user and the system, and the graphical interfaces which deal with the visual representation of the system. The term "Environments" might refer to the overall digital or virtual spaces created by these interfaces <br/>
-Mirroring Cases: <br/>
Scenarios or case studies where interfaces are designed to mirror or replicate certain conditions or settings <br/>
How user actions are mirrored within the system, possibly discussing how input is reflected in the output <br/>
![MainComponentsofMetaverse4](https://github.com/growingpenguin/growingpenguin.github.io/assets/110277903/35b3f579-a0bb-4445-8681-d89123602e9b) <br/>
-Mirror on the screen <br/>
The ability to display the contents of a smartphone's screen on another display <br/>
Whatever you see on your smartphone's screen is exactly what is shown on the TV or monitor <br/>
-Send interaction, send data, flushing in the TV screen <br/>
Process where interactions and data from the smartphone are sent to the TV screen <br/>
Data is transferred quickly and continuously, resulting in the TV screen updating in real-time with what's on the smartphone <br/>
-Smartphone, mirror YouTube, and seen in monitor <br/>
Using the mirroring feature to watch YouTube videos from the smartphone on a larger monitor. Essentially, the video played on the phone is duplicated on the monitor's display <br/>
-Do only one job, phone is controller <br/>
While the smartphone's screen is mirrored to the TV, the phone serves a single purpose - as a controller <br/>
This means you might use the phone to play, pause, or select videos, but the actual viewing takes place on the larger screen of the monitor or TV <br/>











Confusion <br/>
Not meaning, user experience efficient enough <br/>





**Basic Diagram of System** <br/>

With generalization, output can be three types <br/>
1)Within <br/>
Create own world, try to access to the world. Whole thing in the platform, and access into the platform <br/>
2) <br/>
User access to system, interaction will happen <br/>
End to end communication <br/>
=> Confused that metaverse is social networks <br/>
Graphic Module & Virtual Env <br/>
Near end to end with physical object, have difficulty handling <br/>
Physical Object is like a tv screen <br/>
Users flush data, and display images on the display <br/>
-Graphic into data <br/>
More Details.More Interfaces <br/>
Don't bring every pixel, all the data <br/>
Protocol, system, multi-protocol, <br/>

Mirror on the screen <br/>
Send interaction, send data, flushing in the tv screen <Br/>
Smartphon, mirror youtube, and seen in monitor <br/>
Do only one job, phone is controller <br/>


Screen virtual <Br/>


Layer, 3D available, <br/>
Every single one as object <br/>
Object oriented programming, C# <br/>
Layers in Graphic module => Interact system <br/>



**Summary of Metaverse Standards** <br/>

Exit, Screen, Chair, all of them are layers <br/>
Buttons are objected, and can be treated as a layer <br/>



MPEG-V

Sensor: Detect, send data <br/>
MP5 Next version of ~ <br/>
xml few lines of xml architecture <br/>


Interfacing cyber and physical world Working Group <br/>
NO user <br/>
More focus on hardware (sensor and actuator) <br/>

Other <br/>

User doing own thing apart from the actuator



Interfacing cyber and physical <br/>
1~3 working on it <br/>
Other working on it or no <br/>
WIthing standard, partial and not partial working on it <br/>


Some 5G target AR/VR <Br/>
IEEE2828 Not official standard <br/>


Standard vs defecto standard <br/>





Users with devices end users <br/>

User experience <Br/>
10 ~100mbps, have to expected to likely to achieve average up to 10mbps <br/>
=> 1ow data rate crucial in metaverse <br/>

Device <br/>
Receive data <br/>
indexes, structure data to the devices <br/>
Capable of running graphics, data connections <br/>


Not low power application <br/>




Hwo to make it <br/>
How much data processed you might build server <br/>
System <Br/>
Workspace, highly computational & performed <Br/>
Phhusical object need to have on eserver <br/>
System-Server <br/>
Output-Client <br/>
Real problem on operation <br/>
Server is highly power consumed <br/>
Physical object is large scale <br/>
Have only client, connected to the server <br/>
TCP OR HTTP <br/>
http: client & server needed <br/>
Burden object <br/>
Subscribe, publish communication protocol often considered <br/>
Physical Object: Unprocess based on request, command <br/>
Considered in advance to design physical objects <br/>

**Example** <br/>



Enduser, platform , .. <br/>
Provide details <Br/>
FLow diagrams, operate platform > Need to refer my slides <br/>
Use slide information <br/>
Programming, working together, protocol (private network)??? <br/>
Minimized data, what kind of data? Obstacle, monsters? <br/>
