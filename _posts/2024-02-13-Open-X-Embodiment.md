---
layout: post
title:  "Open-X-Embodiment"
---

# Overview
Deepmind partnered with 33 academic labs unveiled this openx embodiment dataset which has been sourced from 22 robot types and RT1X model <br/>
Footnote: <br/>
The concept of "embodiment" refers to giving a digital AI system a physical form, typically in a robot <br/>
This allows the AI to interact directly with the physical world. Unlike traditional AI that operates within computational environments (like playing chess or analyzing data), embodied AI can move, perceive objects, and perform tasks in the real world <br/> 
This is achieved through the robot's sensors and actuators: <br/>
Sensors: <br/>
Allow the robot to gather information from its environment <br/>
This can include visual data from cameras (similar to human eyes), tactile feedback from touch sensors (similar to human skin), or auditory data from microphones (similar to human ears) <br/>
Actuators: <br/>
Enable the robot to perform actions, such as moving its limbs, wheels, or other parts to navigate space, manipulate objects, or interact with its environment in other ways <br/>


Reference: https://www.youtube.com/watch?v=umySOgmrPpI <br/>

